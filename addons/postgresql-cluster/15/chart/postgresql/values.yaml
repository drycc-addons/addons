replicaCount: 3

image:
  # Image was built from registry.drycc.cc/drycc-addons/patroni:3.2
  # https://github.com/zalando/spilo/tree/master/postgres-appliance
  repository: registry.drycc.cc/drycc-addons/postgresql-patroni
  tag: 15
  # IfNotPresent , Always
  pullPolicy: 'IfNotPresent'

# Credentials used by Patroni , passwd
# https://github.com/zalando/patroni/blob/master/docs/SETTINGS.rst#postgresql
# https://github.com/zalando/spilo/blob/master/ENVIRONMENT.rst
credentials:
  superuser: tea
  rewind: cola
  replication: reppasswd

dataname:
  dbname: db1
  username: us1
  password: 111w

# Distribution Configuration stores
# Please note that only one of the following stores should be enabled.
kubernetes:
  endpoints:
    enable: true
  configmaps:
    enable: false

# Extra custom environment variables.
env: {}

#
#custom patroni.yaml used by patroni boot
# configuration: {}
preInitScript: |
  cat > /opt/drycc/postgresql/patroni.yml <<__EOF__
  log:
    level: DEBUG
  bootstrap:
    dcs:
      postgresql:
        use_pg_rewind: true
        use_slots: true
        pg_hba:
        - local all all  peer
        - host all all 0.0.0.0/0 scram-sha-256
        - host replication ${PATRONI_REPLICATION_USERNAME} 0.0.0.0/0 scram-sha-256
        parameters:
          wal_level: hot_standby
          hot_standby: "on"
          max_connections: 1005
          max_worker_processes: 8
          wal_keep_segments: 8
          max_wal_senders: 10
          max_replication_slots: 10
          max_prepared_transactions: 0
          max_locks_per_transaction: 64
          wal_log_hints: "on"
          track_commit_timestamp: "off"
          archive_mode: "on"
          archive_timeout: 1800s
          archive_command: /bin/true
          # timescaledb.license: 'timescale'
          shared_preload_libraries: 'auto_explain,pg_stat_statements'
    initdb:
      - auth-host: scram-sha-256
      - auth-local: trust
      - encoding: UTF8
      - locale: en_US.UTF-8
      - data-checksums
    post_bootstrap: sh /opt/drycc/postgresql/scripts/post_init.sh
  restapi:
    connect_address: '${PATRONI_KUBERNETES_POD_IP}:8008'
  postgresql:
    connect_address: '${PATRONI_KUBERNETES_POD_IP}:5432'
    authentication:
      superuser:
        username: postgres
        password: '${PATRONI_SUPERUSER_PASSWORD}'
      replication:
        username: standby
        password: '${PATRONI_REPLICATION_PASSWORD}'
      rewind:  # Has no effect on postgres 10 and lower
        username: rewinder
        password: '${PATRONI_REWIND_USERNAME}'
  watchdog:
    mode: off
  __EOF__

postInitScript: |
  #!/bin/bash
  set -Eeu
  # Create monitor user
  psql -w -c  "CREATE USER tea_mon WITH ROLE pg_monitor"
  # Create init database & user 
  if [[( -n "$DATABASE_USER") &&  ( -n "$DATABASE_PASSWORD") && ( -n "$DATABASE_NAME")]]; then
    echo "Creating user ${DATABASE_USER}"
    psql -w -c "create user ${DATABASE_USER} WITH LOGIN ENCRYPTED PASSWORD '${DATABASE_PASSWORD}'"
    echo "Creating database ${DATABASE_NAME} "
    psql -w -c "CREATE DATABASE ${DATABASE_NAME} OWNER ${DATABASE_USER} CONNECTION LIMIT 1000"
    psql -w -d ${DATABASE_NAME} -c "create extension postgis"
    psql -w -c  "CHECKPOINT;CHECKPOINT;"
  else
    echo "Skipping user creation"
    echo "Skipping database creation"
  fi

walE:
  # Specifies whether Wal-E should be enabled
  enable: false
  # Cron schedule for doing base backups
  scheduleCronJob: 00 01 * * *
  # Amount of base backups to retain
  retainBackups: 2
  # Path to the S3 or GCS bucket used for WAL-E base backups
  s3Bucket:
  gcsBucket:
  # Name of the secret that holds the credentials to the bucket
  kubernetesSecret:
  # Maximum size of the WAL segments accumulated after the base backup to
  # consider WAL-E restore instead of pg_basebackup
  backupThresholdMegabytes: 1024
  # Maximum ratio (in percents) of the accumulated WAL files to the base backup
  # to consider WAL-E restore instead of pg_basebackup
  backupThresholdPercentage: 30

persistentVolume:
  enabled: false
  size: 10G
  ## database data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  subPath: ""
  mountPath: "/home/postgres/pgdata"
  annotations: {}
  accessModes:
    - ReadWriteOnce

resources: 
  # If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    cpu: 1000m
    memory: 1Gi
    # hugepages-2Mi: 4Mi
  requests:
    cpu: 1000m
    memory: 1Gi

# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
nodeSelector: {}

# https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []

# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinityTemplate: |
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        topologyKey: "kubernetes.io/hostname"
        labelSelector:
          matchLabels:
            app:  {{ template "patroni.name" . }}
            release: {{ .Release.Name | quote }}
affinity: {}

## Use an alternate scheduler, e.g. "stork".
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
# schedulerName:

rbac:
  # Specifies whether RBAC resources should be created
  create: true

serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true
  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

## Postgresql Prometheus exporter parameters
##
metrics:
  enabled: false
## Postgresql Nework Policy configuration
##
networkPolicy:
  ## @param networkPolicy.enabled Enable creation of NetworkPolicy resources
  ##
  enabled: true 
  ## @param networkPolicy.allowExternal The Policy model to apply.
  ## When set to false, only pods with the correct
  ## client label will have network access to the port MySQL is listening
  ## on. When true, MySQL will accept connections from any source
  ## (with the correct destination port).
  ##
  allowCurrentNamespace: true
  allowNamespaces: []